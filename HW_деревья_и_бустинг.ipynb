{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FilatovArtem/MTS_ML-Course/blob/main/HW_%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D1%8C%D1%8F_%D0%B8_%D0%B1%D1%83%D1%81%D1%82%D0%B8%D0%BD%D0%B3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Деревья"
      ],
      "metadata": {
        "id": "sBGXNPpgHKfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим вопрос как на самом деле происходит сплит по непрерывной фиче в дереве\n",
        "\n",
        "Не будем останавливаться на всех возможных реализациях обучения деревьев\n",
        "\n",
        "*   ID3\n",
        "*   CART (с модификациями используется в sklearn)\n",
        "*   C4.5 (J48)\n",
        "*   C5.0\n",
        "*   CN2\n",
        "*   CHAID\n",
        "*   Symmetric/Oblivious Trees (catboost)\n",
        "\n",
        "Рассмотрим только вопрос сплита\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Давайте напишем пару вспомогательных функций"
      ],
      "metadata": {
        "id": "OvV3sDdjHLwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "from operator import itemgetter"
      ],
      "metadata": {
        "id": "3aZooTYfIYFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VERY_BIG = 1e90"
      ],
      "metadata": {
        "id": "9mSrwcseZqY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_criterion(x, x_treshold, target, type = 'entropy'):\n",
        "  assert len(x) == len(target)\n",
        "  if type not in ['MSE', 'entropy', 'gini_impurity']:\n",
        "    return 'incorrect criterion type'\n",
        "  x = pd.Series(x)\n",
        "  target = pd.Series(target, index = x.index)\n",
        "  target_left, target_right = target[x < x_treshold], target[x >= x_treshold]\n",
        "  if (not len(target_left)) or (not len(target_left)):\n",
        "    return VERY_BIG\n",
        "  if type == 'MSE':\n",
        "    x_left, x_right = x[x < x_treshold], x[x >= x_treshold]\n",
        "    prediction_left, prediction_right = np.mean(x_left), np.mean(x_right)\n",
        "    mse_left, mse_right = sum((target_left - prediction_left) ** 2), sum((target_right - prediction_right) ** 2)\n",
        "    return (len(target_left) * mse_left + len(target_right) * mse_right) / len(target)\n",
        "\n",
        "  p_left, p_right = np.mean(target_left), np.mean(target_right)\n",
        "  if type == 'gini_impurity':\n",
        "    return 1 - (p_left ** 2 + p_right ** 2)\n",
        "  if type == 'entropy':\n",
        "    if (not p_left) or (not p_right):\n",
        "      return VERY_BIG\n",
        "    else:\n",
        "      return -p_left * np.log2(p_left) -p_right * np.log2(p_right)"
      ],
      "metadata": {
        "id": "bCyxrkAIHKn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте посмотрим на выбор сплита перебором порога в задаче классификации"
      ],
      "metadata": {
        "id": "GK-URMHkPsmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature = [5, 6, 7, 8, 9, 10, 2]\n",
        "target = [1, 0, 1, 0, 1, 1, 1]\n",
        "t = []\n",
        "for feature_treshold in feature[0:-1]:\n",
        "  t.append([feature_treshold, split_criterion(feature, feature_treshold, target, type = 'entropy')])\n",
        "t = sorted(t, reverse = True, key = itemgetter(1))\n",
        "print(tabulate(t, headers = ['Порог', 'Значение критерия']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzs3zhDWIKQl",
        "outputId": "2c6560d8-c6ef-4b18-d2e4-c3c145ca3da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Порог    Значение критерия\n",
            "-------  -------------------\n",
            "      7             0.701253\n",
            "      8             0.701253\n",
            "      6             0.442179\n",
            "      9             0.442179\n",
            "      5             0.389975\n",
            "     10             0.389975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте убедимся что пороги 5 и 10 одинаково хорошо разбивают дерево, посчитаем для этого частоту единичек в поддеревьях"
      ],
      "metadata": {
        "id": "-j2lp7qxPQrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature = pd.Series(feature)\n",
        "target = pd.Series(target, index = feature.index)\n",
        "print(np.mean(target[feature < 5]), np.mean(target[feature >= 5]))\n",
        "print(np.mean(target[feature < 10]), np.mean(target[feature >= 10]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kVtn9_jIWpz",
        "outputId": "3c8bad99-0e76-48f4-831b-c4ea7d9b2172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.6666666666666666\n",
            "0.6666666666666666 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь перейдем непосредственно к стратегиям сплитов"
      ],
      "metadata": {
        "id": "JEao-rW6RyDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification"
      ],
      "metadata": {
        "id": "vQZtUIh9JEG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 88\n",
        "x, y = make_classification(5_000, 10, random_state = random_state)"
      ],
      "metadata": {
        "id": "Wsy3R3JGVQSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь реализуем самую простую стратегию выбора первого узла дерева"
      ],
      "metadata": {
        "id": "R3Luxd6vVgEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "best_splits = []\n",
        "for idx_feature, feature in enumerate(x.T):\n",
        "  t = []\n",
        "  for feature_treshold in feature[0:-1]:\n",
        "    t.append([feature_treshold, split_criterion(feature, feature_treshold, y, type = 'entropy')])\n",
        "  best_split_index = np.nanargmin(np.array(t)[:, 1], axis = 0)\n",
        "  best_splits.append([idx_feature, t[best_split_index][0], t[best_split_index][1]])\n",
        "best_splits = sorted(best_splits, reverse = True, key = itemgetter(1))\n",
        "print(tabulate(best_splits, headers = ['Feature', 'Порог', 'Значение критерия']))\n",
        "print('the winner is')\n",
        "best_of_best_split = np.nanargmin(np.array(best_splits)[:,2], axis = 0)\n",
        "print(tabulate([best_splits[best_of_best_split]], headers = ['Feature', 'Порог', 'Значение критерия']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMSoPiDSVfaU",
        "outputId": "f94456d1-31d5-49af-c92a-368cae9690e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Feature     Порог    Значение критерия\n",
            "---------  --------  -------------------\n",
            "        1   4.34112             0.499956\n",
            "        9   4.18103             0.499956\n",
            "        6   3.51631             0.499956\n",
            "        2   3.46727             0.499956\n",
            "        5   3.24306             0.964164\n",
            "        4   2.29289             0.499956\n",
            "        7  -1.10045             0.468756\n",
            "        8  -3.53499             0.499956\n",
            "        3  -3.54405             0.499956\n",
            "        0  -3.85811             0.499956\n",
            "the winner is\n",
            "  Feature     Порог    Значение критерия\n",
            "---------  --------  -------------------\n",
            "        7  -1.10045             0.468756\n",
            "CPU times: user 38.8 s, sys: 92.7 ms, total: 38.9 s\n",
            "Wall time: 44.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Долго считалось!!\n",
        "\n",
        "Мы перебрали все фичи и все пороги -> всего около 5 000 сплитов"
      ],
      "metadata": {
        "id": "zlOaLSUvZ8jS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как подсчитать радикально быстрее?\n",
        "\n",
        "Через гистограммы, но это будет другое дерево, точность упадет\n",
        "\n",
        "Подсказка: используйте функцию pd.qcut"
      ],
      "metadata": {
        "id": "shlLPC12zTMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "best_splits = []\n",
        "for idx_feature, feature in enumerate(x.T):\n",
        "  t = []\n",
        "  _, bins = pd.qcut(feature, q=128, retbins=True, duplicates='drop')\n",
        "  for feature_treshold in bins:\n",
        "    criterion_val = split_criterion(feature, feature_treshold, y, type='entropy')\n",
        "    t.append([feature_treshold, criterion_val])\n",
        "  best_split_index = np.nanargmin(np.array(t)[:, 1], axis=0)\n",
        "  best_splits.append([idx_feature, t[best_split_index][0], t[best_split_index][1]])\n",
        "best_splits = sorted(best_splits, reverse = True, key = itemgetter(1))\n",
        "print(tabulate(best_splits, headers = ['Feature', 'Порог', 'Значение критерия']))\n",
        "print('the winner is')\n",
        "best_of_best_split = np.nanargmin(np.array(best_splits)[:,2], axis = 0)\n",
        "print(tabulate([best_splits[best_of_best_split]], headers = ['Feature', 'Порог', 'Значение критерия']))"
      ],
      "metadata": {
        "id": "OQC8V5KtD4nr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cecde51-cf03-4dfa-a44b-9e178966a6b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Feature     Порог    Значение критерия\n",
            "---------  --------  -------------------\n",
            "        1   4.34112             0.499956\n",
            "        9   4.18103             0.499956\n",
            "        6   3.51631             0.499956\n",
            "        2   3.46727             0.499956\n",
            "        4   2.29289             0.499956\n",
            "        5   2.08983             0.98471\n",
            "        3   1.76306             0.974604\n",
            "        8  -1.01648             0.990269\n",
            "        7  -1.10756             0.470641\n",
            "        0  -2.3691              0.524808\n",
            "the winner is\n",
            "  Feature     Порог    Значение критерия\n",
            "---------  --------  -------------------\n",
            "        7  -1.10756             0.470641\n",
            "CPU times: user 926 ms, sys: 3.07 ms, total: 929 ms\n",
            "Wall time: 950 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: при числе бинов в гистограмме равной 128 какая фича окажется в корне дерева?"
      ],
      "metadata": {
        "id": "wFe-cAPbzvG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   feature_0\n",
        "2.   feature_1\n",
        "3.   feature_2\n",
        "4.   feature_3\n",
        "5.   feature_4\n",
        "6.   feature_5\n",
        "7.   feature_6\n",
        "8.   feature_7 <--\n",
        "9.   feature_8\n",
        "10.  feature_9"
      ],
      "metadata": {
        "id": "rYBnGMfB0ISG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Стратегии выбора порогов очень разные, например в catboost:\n",
        "\n",
        "https://catboost.ai/docs/en/concepts/quantization"
      ],
      "metadata": {
        "id": "LZfei9lu9JDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Градиентный бустинг"
      ],
      "metadata": {
        "id": "87tvSz5k3Yih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Мы же с вами здесь реализуем базовый кейс -- градиентный бустинг в задаче регресии\n"
      ],
      "metadata": {
        "id": "_kICdurW5POW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "5WwWIo_Ia61L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class simple_gradient_boosting_regressor():\n",
        "  def __init__(self, n_estimators = 20, max_depth = 5, learning_rate = 0.2, random_state = 55):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.max_depth = max_depth\n",
        "    self.random_state = random_state\n",
        "    self.n_estimators = n_estimators\n",
        "    self.trees = []\n",
        "\n",
        "  def fit(self, x, y, verbose = True):\n",
        "    preds = np.mean(y)\n",
        "    for idx in range(self.n_estimators):\n",
        "      current_tree = DecisionTreeRegressor(\n",
        "                max_depth=self.max_depth,\n",
        "                random_state=self.random_state\n",
        "            )\n",
        "      residuals = y - preds\n",
        "      current_tree.fit(x, residuals)\n",
        "      self.trees.append(current_tree)\n",
        "      preds += self.learning_rate * current_tree.predict(x)\n",
        "      if verbose:\n",
        "        mse = mean_squared_error(y, preds)\n",
        "        print(f'MSE after {idx} tree is {mse:.3f}')\n",
        "\n",
        "  def predict(self, x):\n",
        "    preds = np.zeros(x.shape[0])\n",
        "    for tree in self.trees:\n",
        "      preds += self.learning_rate * tree.predict(x)\n",
        "    return preds"
      ],
      "metadata": {
        "id": "Chibnqto9AEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 55\n",
        "x, y = make_regression(1000, 5, random_state = random_state)"
      ],
      "metadata": {
        "id": "3KjNUz6z9AgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbr = simple_gradient_boosting_regressor()\n",
        "gbr.fit(x, y)"
      ],
      "metadata": {
        "id": "vw6eRGRXEUdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a4019ca-2c12-43a8-e58a-2d8da0188953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE after 0 tree is 11217.737\n",
            "MSE after 1 tree is 7910.404\n",
            "MSE after 2 tree is 5650.280\n",
            "MSE after 3 tree is 4118.589\n",
            "MSE after 4 tree is 3032.511\n",
            "MSE after 5 tree is 2233.586\n",
            "MSE after 6 tree is 1676.377\n",
            "MSE after 7 tree is 1283.969\n",
            "MSE after 8 tree is 984.848\n",
            "MSE after 9 tree is 774.297\n",
            "MSE after 10 tree is 603.629\n",
            "MSE after 11 tree is 483.340\n",
            "MSE after 12 tree is 392.615\n",
            "MSE after 13 tree is 321.182\n",
            "MSE after 14 tree is 267.361\n",
            "MSE after 15 tree is 226.771\n",
            "MSE after 16 tree is 193.463\n",
            "MSE after 17 tree is 169.164\n",
            "MSE after 18 tree is 149.315\n",
            "MSE after 19 tree is 132.892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание:**\n",
        "Во сколько раз упала ошибка MSE на трейне при параметрах, указанных в коде?\n",
        "\n",
        "\n",
        "\n",
        "1.   Не упала\n",
        "2.   Упала менее чем в 2 раза\n",
        "3.   Упала от 2х до 10 раз\n",
        "4.   Упала от 10 до 100 раз <--\n",
        "5.   Упала от ста до тысячи раз\n",
        "6.   Упала более чем в тысячу раз\n",
        "\n"
      ],
      "metadata": {
        "id": "7ctzBeQRC6hm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для активно интересующихся и скучающих пара статей на русском\n",
        "\n",
        "https://habr.com/ru/articles/799725/\n",
        "\n",
        "https://habr.com/ru/companies/vk/articles/438562/"
      ],
      "metadata": {
        "id": "YQ0EJNeQ8C67"
      }
    }
  ]
}